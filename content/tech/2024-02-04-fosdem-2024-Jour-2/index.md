---
title: "FOSDEM 2024 - Jour 2"
date: 2024-01-04T19:00:00+01:00
image: "fosdem-ulb.png"
---

Cet article fait partie d'une sÃ©rie d'articles concernant le FOSDEM 2024.
* [Jour 1]({{< relref "tech/2024-02-03-fosdem-2024-Jour-1">}})
* Jour 2 (Vous Ãªtes ici ! ğŸ¯)

Pour cette seconde journÃ©e, nous allons parler principalement de monitoring et d'observabilitÃ©.

# Welcome to the Monitoring & Observability devroom - Richard "RichiH" Hartmann

8e devroom sur le sujet. La thÃ©matique annoncÃ©e pour cette annÃ©e est moins sur la rÃ©volution mais plus sur de l'Ã©volution et comment appliquer les technos qui ont Ã©mergÃ©es ces derniÃ¨res annÃ©es sur les workloads que l'on peut rencontrer couramment dans nos entreprises.

# Auto Instrumentation for your NodeJS Application on Kubernetes - Yuri Oliveira Sa

On commence par un rappel de l'architecture d'OpenTelemetry (receivers, les collectors composÃ©s de processors et exporters,...).

Yuri prÃ©sente l'utilisation de l'opÃ©rateur OpenTelemetry et l'utilisation des CRD `OpenTelemetryCOllector` et `Instrumentation`.

Il suffit d'ajouter une annotation sur les pods et l'instrumentation automatique est injectÃ©e dans le pod sans mÃªme avoir Ã  modifier l'application. (Par contre, si vous avez besoin d'ajouter des spans par exemple, ben... faudra modifier l'application Ã©videmment).

# When Prometheus Met OpenTelemetry - Pavol Loffay

L'objectif de cette prÃ©sentation est de montrer que passer de Prometheus Ã  OpenTelemetry n'est pas chose facile du fait des diffÃ©rences de conception, notamment pour les metrics en delta temporality.

DÃ©mo : montrer les diffs entre une exposition Prometheus simple d'une app Go puis ce qui revient aprÃ¨s passage dans le collector.

En gros, pour rÃ©sumer ma comprÃ©hension, on en conclut un peu ce qui pourrait paraÃ®tre logique : mieux vaut exporter en OTLP depuis les applications pour ensuite laisser le collector exporter vers Prometheus vs. utiliser le receiver Prometheus pour faire une conversion vers Prometheus ensuite (ou garder le scrape direct Ã©videmment). Les impacts sont loin d'Ãªtre neutres mÃªme si un `TargetAllocator` peut aider Ã  conserver une partie des labels sur les timeseries (et Ã©viter de faire des jointures complexes avec les timeseries `target_info`).   

# Strategic Sampling: Architectural Approaches to Efficient Telemetry - Benedikt Bongartz, Julius Hinze

Plusieurs stratÃ©gies possibles :
* **head-based sampling** : dÃ©cision prise au dÃ©but de la trace (mais on ne peut pas prendre en compte le statut de la trace - error ou pas par exemple - dans le sampling)
* **tail-based sampling** : dÃ©cision prise Ã  la fin de la trace (mais demande un surcoÃ»t car la dÃ©cision doit Ãªtre prise avec tous les spans de la trace + peut Ãªtre gÃªnant pour les long-running process si la dÃ©cision est prise au bout d'un temps donnÃ© par exemple)

L'objectif de cette dÃ©mo est de montrer comment on peut essayer d'utiliser le tail-based sampling Ã  l'Ã©chelle. Pas mal d'idÃ©es, avec du load-balancing basÃ© sur du consistent hashing, en mettant un Kafka topic par pod au milieu aussi, mais c'est vraiment un problÃ¨me compliquÃ© Ã  rÃ©soudre.

Un talk super intÃ©ressant sur un use-case pourtant trÃ¨s classique.

# Practical CI/CD Observability with OpenTelemetry - Dimitris Sotirakis, Giordano Ricci

Pas dans la mÃªme salle (puisqu'il s'agit de la devroom Testing & Continuous delivery), mais un peu le mÃªme sujet quand mÃªme finalement ğŸ˜ƒ

On commence par la traditionnelle question "C'est quoi la CI ?" (Ã§a doit Ãªtre le "peut-on rire de tout ?" des informaticiens ğŸ˜…).

L'idÃ©e du talk est de dire que l'observabilitÃ© se concentre pour le moment sur la partie run, et peut-Ãªtre faudrait-il faire un "focus-shift" vers la partie "test & deploy".

Et donc... remonter les donnÃ©es de mÃ©trologie des environnements de CI et des builds via un collector OpenTelemetry.
Dans leur cas, Ã§a veut dire crÃ©er un receiver pour leurs environements de CI. Il en existe pour Jenkins et Drone par exemple, et sans doute pour d'autres aussi.

L'objectif est de pouvoir tracer de quel PR provient un test devenu flacky par exemple, ou suivre la performance des builds, ou encore suivre le code coverage dans le temps (mÃªme si des outils comme Sonarqube font dejÃ  Ã§a trÃ¨s bien, mais c'est un talk de Grafana, donc ils poussent leurs solutions ğŸ˜‰)

Point intÃ©ressant : un working group a commencÃ© Ã  bosser sur de la sÃ©mantique des attributs pour le champ de la CI/CD dans OpenTelemetry. J'imagine que Ã§a ne va pas se faire rapidement, mais c'est bien que ce genre d'initiative existe.

# Whatâ€™s possible in observability when we have frame pointers - Matthias Loibl, Jon Seager

Retour en dev room "Monitoring & observability".

Les Frame pointers sont les pointeurs qui permettent de connaÃ®tre la call stack quand on est en train d'exÃ©cuter un programme. L'idÃ©e est d'utiliser eBPF pour faire du profiling avec un overhead assez bas, et mÃªme du debuggage.

Ubuntu 24.04LTS aura les frame pointers actifs par dÃ©faut sur les plateformes 64bits. Certains outils comme bpftrace seront installÃ©s par dÃ©faut (sauf peut-Ãªtre sur les images minimales).

Je n'ai pas les compÃ©tences suffisantes pour voir si c'est vraiment intÃ©ressant ou pas en production. A voir...

# Modern application observability with Grafana and Quickwit - FranÃ§ois Massot

FranÃ§ois revient sur le problÃ¨me de cardinalitÃ© qui arrive rapidement sur les mÃ©triques (et si vous avez dÃ©jÃ  fait un peu de Prometheus dans Kubernetes, vous voyez sans doute ce dont il parle ğŸ˜„)

Il prÃ©sente Quickwit, un moteur de stockage pour logs et traces et qui s'appuie sur un object storage.

Comme d'habitude, les temps de rÃ©ponse ont l'air trÃ¨s intÃ©ressants, mais Ã©videmment Ã§a demande de faire du benchmark soi-mÃªme pour se rendre compte.

Le pauvre a eu des soucis de vidÃ©o avant son talk, Ã§a n'a clairement pas dÃ» Ãªtre facile pour lui.

# What is CI/CD observability, and how to bring observability to CI/CD pipelines? - Dimitris Sotirakis, Giordano Ricci

Les mÃªmes que plus tÃ´t dans la journÃ©e, mais dans une autre salle ! ğŸ¤”

Eh ben vous savez quoi ? Ils ont redit **exactement** la mÃªme chose :joy:

&lt;mode rÃ¢leur&gt; Je trouve le procÃ©dÃ© malhonnÃªte de prendre 2 slots de conf, avec des titres diffÃ©rents, pour prÃ©senter **exactement** le mÃªme set de slides. Ca fait un sujet de moins qui aura pu Ãªtre traitÃ©. Bref, c'est naze ! &lt;/mode rÃ¢leur&gt;

# C'est finito !

C'est sur ce talk Ã©nervant que cet Ã©dition du FOSDEM. AprÃ¨s l'effort, le rÃ©confort.

![Un peu de rÃ©confort](effort-reconfort.png)

Ce fut une Ã©dition sympa, faites d'inspiration, de discussions et de bons moments (pas tous alcoolisÃ©s hein! Ne soyez pas mÃ©disants s'il vous plaÃ®t ğŸ˜…).

Un point important : le FOSDEM est une confÃ©rence elle-mÃªme open-source, et l'ensemble des replays devraient Ãªtre disponibles rapidement sur [le site du FOSDEM](https://fosdem.org/2024/). Rendez-vous sur la page de chaque talk pour le trouver dÃ¨s qu'il est disponible. C'est d'autant plus important que, comme je le disais en prÃ©ambule du jour 1, il y a un nombre trÃ¨s important de talks sur le week-end, sur des sujets aussi divers que des technologies, des problÃ©matiques sociÃ©tales autour de l'open-source et des technologies de l'information, des domaines juridiques, etc... C'est sans doute la confÃ©rence la plus riche et la plus diverse qui existe Ã  ma connaissance.

Comme toutes les bonnes choses ont une fin, me voilÃ  au moment oÃ¹ j'Ã©cris ces lignes dans l'Eurostar du retour pour Paris, la tÃªte pleine d'envie de tester des trucs, d'implÃ©menter ce que j'ai pu voir ce week-end et de lancer des sujets d'amÃ©lioration chez mon employeur prÃ©fÃ©rÃ© (bon ok, c'est le seul que j'ai en mÃªme temps).

A bientÃ´t pour de nouvelles aventures !
